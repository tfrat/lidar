{"name":"Ground Plane Segmentation from Unstructured Point Clouds","tagline":"Tim Fratangelo & Bret Minnehan","body":"# 1. Overview and Goals\r\n\r\nLiDAR (Light Detection and Ranging) sensors use time of flight measurements from a focused beam of light from a laser to measure the three-dimensional structure of an object or area.  LiDAR sensors have broad application to many domains including Archeology, Robotics, and Physics. As LiDAR sensors are decreasing in price and weight their use from aerial platforms is increasing. Aerial LiDAR imagery provides high-resolution topographic data for much cheaper than other methods. The data collected from LiDAR sensors are known as Point Clouds. Point Clouds are a series of points represented by their coordinates in the 3D Cartesian coordinate system.\r\n \r\nThis work is focused on processing the data collected from airborne LiDAR sensors to segment points belonging to the ground plane to points belonging to objects or structures. This ground plane segmentation is useful for many different applications, such as surveying, in which the area of focus is purely the ground plane. A traditional approach for ground plane segmentation can be seen in Figure 1. This figure demonstrates how an initial point cloud is input into a system then it is preprocessed using various methods such as normalization and resampling to insure consistency of point clouds for the system. After the point cloud is pre-processed it is filtered using one of many filtering methods. After filtering it is then a plane fitting method is used to find the plane that best fits the majority of the data. After the plane is fit to the data a segmentation algorithm is used to extract the points that are consistent with the plane given various constraints. After the segmentation the points are feed into a mesh generation algorithm, which generates a triangulated mesh from the points on the ground plane. The aim of this work was to test multiple commonly used methods for each of these steps and determine which methods were optimal, as will be discussed for the remainder of the work.\r\n\r\n![Pipeline](https://drive.google.com/uc?id=0B4VJB4X3lwZGQ1BKMEN0akoxc0U)\r\n\r\nThe remainder of this site is organized as such: Section 2 discusses the configuration of the system used and the computer used for processing. Section 3 discusses the methods used for filtering the initial point cloud. Section 4 discusses the approaches for estimating the ground plane. Section 5 discusses the ground plane segmentation process. Section 6 outlines the steps taken for generating 3D triangulated meshes from a point cloud. Section 7 discusses the results from this work. Section 8 overviews some of the challenges encountered in this work. Finally Section 9 provides potential avenues for future work and Section 10 concludes. \r\n\r\n# 2. Setup\r\n\r\nIn this work we relied heavily on an open source C++ library known as the Point Cloud Library (PCL), which is supported by many large corporations in the 3D sensing industry. The library was compiled and used on a virtual machine running Ubuntu 15.04 with 16GB RAM, Intel i5 Processor.\r\n\r\n# 3. Filtering\r\n### Passthrough Filter\r\n\r\nThe passthrough filter relies on thresholding to eliminate points along a dimensional axis. By providing an upper and lower limit all points not within those bounds will be removed from the plot. Utilizing this filter for this project is not very beneficial as most LiDAR datasets deal with changes in elevation. As a result the data generally does not lie on a single plane. When the filter is applied, not only noise is eliminated but also important terrain points are removed as well.\r\n\r\n### Radius Outlier Removal\r\n\r\nThe radius outlier removal algorithm measures the amount of local neighbors for each point. A point can be considered to have neighbors is they lie within a preset spherical radius. If there are not enough neighbors within the radius the point is removed from the cloud. This works well with removing isolated outliers. However if there are a clusters of noise they will not be filtered out.\r\n\r\n### Statistical Outlier Removal\r\n\r\nThe statistical outlier removal algorithm filters is useful for removing measurement errors from LiDAR scans. This is done on a point by point basis. At each point the distance between each neighbor is used to calculate the mean and standard deviation. The amount of nearest neighbors for each point is passed as an argument to the algorithm along with the standard deviation threshold. If the point’s mean distance is larger than the standard deviation threshold \r\n\r\n# 4. Plane Estimation\r\n\r\nThe concept behind the plane estimation problems is attempting to find a planer model that best fits the input data. Plane estimation should theoretically be a simple task if the data is planar and noise free; however the point clouds resulting from LiDAR scans rarely fit such conditions. Due to the inconsistencies of the ground in most environments and the inherent noise in LiDAR data more robust planer estimation algorithms must be used. The PCL library implements multiple robust model fitting algorithm including, Least Median of Squares (LMEDS), Random Sample and Consensus (RANSAC), and Progressive Sample and Consensus (PROSAC). Each of these algorithms will be discussed further below. \r\n        \tThe simplest of the three algorithms is Least Median of Squares[CITE], in this algorithm points in the dataset are randomly sampled in m groups which are then used to form m estimations for the model of the data. Once the models are calculated the residual for each point with respect to each model, how close is the point to fitting the model, is calculated. The score for each model is then determined by calculating the median of the residuals for all of the points. The median is used as opposed to the mean because the median has been shown to be more robust to outliers than the mean. The model that has the smallest median residual is then selected as the optimal model for the data.\r\nOne of if not the most used model fitting algorithms is the Random Sample and Consensus algorithm. Unlike LMEDS, RANSAC is an iterative probabilistic method for model fitting. In the RANSAC algorithm an initial set of point are randomly selected from the complete dataset, the set selected is the minimal set that will solve for the given parameters for the model. Once a model is fit to the initial set the residuals for all of the remaining points are calculated. Any point whose residual falls within a specified threshold is considered an inlier point, part of the consensus set, all other points are considered outliers. If a specified number of inliers are found the algorithm then attempts to update the model given the updated set, including the new inliers, then the residuals are recalculated and new inliers are added. This process repeats until a minimum confidence value is achieved on the model’s fit or a maximum number of iterations were reached. This method was originally designed for image alignment based on match landmarks in [Fischler], but has been adapted for countless applications that require fitting a model to data.  \r\nThe model-fitting algorithm used in this work that was most recently proposed was the Progressive Sample and Consensus algorithm [Chum]. The PROSAC method is an extension to the RANSAC method, with a slight alteration to the sampling procedure. Unlike RANSAC, which samples all point with equal probability, PROSAC relies on the quality of the correspondences selecting the points with the minimal residuals initially and progressively growing the set larger.  \r\n\r\n# 5. Segmentation\r\n### Graph Cuts\r\n\r\nOne of the most common modern segmentation techniques is an algorithm known as Graph Cuts (or Min cut/Max flow), popularized by [Boykov]. This algorithm is popular due to its adaptability and applicability to many problem domains. For the Graph Cuts algorithm a node on a bi-directional graph represents each point. Between each point is a connection that has a weight corresponding to the similarity between the two nodes. Part of the adaptability of the graph cuts method comes from the fact that the weighting function can be an arbitrary function that highlights desired seminaries between points. In image data it is common to connect each pixel with its surrounding pixels using the similarity of the intensity values as the weight metric.  For point clouds often the three dimensional Euclidian distance is used for the intra-point weights, as was done in this implementation. Unfortunately for the implementation of graph cuts supplied by PCL the weight metric could not be altered, which negatively affected the quality of results it produced. In addition to the intra-point weights there are also weights between each point and Source and Drain nodes. In most cases these weights can be determined using an arbitrary metric; however in this implementation the weights were determined based on the 3D Euclidian distance to “source points”. The goal of the graph cuts algorithm is to separate the graph into two subgraphs, one connected the source and one connected to the drain, with the minimal cut cost. For our implementation we were forced to use the 3D Euclidian distance for the weight metric and for the source points we used the inlier points from the plane estimation stage. \r\n\r\n### Progressive Morphological Filter\r\n\r\nProgressive Morphological filters work to eliminate points that are not considered to be apart of the terrain in a point cloud data set. This is accomplished by using multiple iterations of a mathematical morphological filter on a two-dimensional grayscale image [4]. This image is a top-down view of the LiDAR data set using the brightness of each pixel as the elevation value. Changes in elevation can be directly correlated to changes in graytone in the image. The morphological filter works by performing two operations, dilation and erosion. Dilation replaces the current pixel with the maximum value of the neighboring pixels surrounding it and erosion does the opposite and uses the minimum value. These two operations can be used in conjunction to create opening and closing techniques to filter LiDAR data. Opening consists of first eroding the image and then dilating, whereas closing is in the opposite order. By performing these two techniques small objects can be removed by erosion and then large terrain objects such as cliff faces can be restored using dilation. This technique is highly dependent on the window size used to select neighboring pixels. A window size too small can remove small objects on the ground but large objects such as buildings will remain. However, a large window size can remove valid ground points. As a pixel gains its value from the highest or lowest point in a certain window size it is of paramount importance that the dataset is filtered prior to running this algorithm. \r\n\r\nChoosing a proper window size with a real world data set to accurately filter ground points cannot be feasible found. This problem is solved by using multiple iterations of the morphological filter using increased window sizes with each subsequent iteration. Each iteration feeds it output into the next run. The first few runs will removed the small objects in the scene such as trees or cars but will leave buildings in. Since those objects have been removed in previous iterations the larger window sizes will only encounter ground and properly iterate. The window size will eventually increase to a size that will encompass the tops of the buildings and they will be removed as well. This continues until a maximum window size has been reached. It is important to only choose a final window size that is just large enough to remove the largest object in the scene as to avoid over removing ground points. \r\n\r\nA problem with this approach is that terrain with gradual increases in elevation have their tops flattened into a plateau shape. This is overcome by adding a elevation threshold parameter to the algorithm. The original point’s elevation is compared to the new filtered point’s elevation. If the difference is smaller than the threshold it is considered a ground point, otherwise it is removed. The threshold size also starts small and increases with each pass. This is to avoid keeping short objects such as trees in the first few passes. The result is an algorithm that can keep natural changes in elevations while removing unwanted objects. \r\n\r\n# 6. Mesh Generation\r\n\r\nIn Computer Graphics its important to utilize simple shapes wherever possible in order to make rendering and computations easier. Triangles are a perfect shape to use as they are easy to compute with and when using enough triangles almost any other shape can be created. Therefore it is important to utilize triangulation to help visualize our data sets. By triangulating the final ground plane point cloud an accurate model can be generated to assist with visualization. A fast triangulation of unordered point clouds algorithm was used to generate this model. This consists of first placing all of the points in a list of unconnected points. Each point in the list checks within a given radius for neighboring points. Triangles are then generated using these neighboring points as long as the triangles created do not have inner angles larger than the set maximum angle size. As triangles are generated the points involved in the triangle are removed from the list. Once the list is empty the mesh generation has completed.\r\n\r\n# 7. Results\r\n### Filtering\r\nOf the three filtering algorithms used statistical outlier removal performed the best. Passthrough thresholding generated an incomprehensible point cloud that generally did not resemble the input point cloud. The radius outlier removal algorithm performed much better and was able to remove a majority of noise surrounding the data set. Only tightly packed clusters of anomalous data points were left unfiltered. Statistical outlier removal however performed the best and removed almost all noise. A comparison between the original point cloud, radius and statistical can be seen in Figures _, _ and _ respectively. \r\n\r\n![Original Filter](https://drive.google.com/uc?id=0B4VJB4X3lwZGalB0bkctbUZ1WDQ)\r\n\r\n![Radius Filter](https://drive.google.com/uc?id=0B4VJB4X3lwZGZm53VTFTRXZTMEU)\r\n\r\n![Statistical Filter](https://drive.google.com/uc?id=0B4VJB4X3lwZGU1hIOFBpUlZCeFU)\r\n\r\nEach algorithm was run on data sets of increasing size. Figure _ shows the timing results on datasets ranging from 7492 points to over 480k points. Since the passthrough filter is simply a thresholding procedure it performed very quickly at all point amounts. The radius outlier removal algorithm had very strange results and showed how difficult it is to compare data sets based on size. Instead of following an increasing trend the timing results for the radius implementation would increase and decrease as the point size increased. One explanation for this behavior is that the radius outlier removal algorithm performs more poorly when the dataset contains dense points. The runtime of the statistical outlier removal algorithm follows more traditional trend. As the size of the dataset increases the time increases as well. Only the radius and statistical outlier removal algorithms are comparable. For large data sets the radius removal algorithm will perform better than the statistical algorithm. However this is highly dependent on the density of the points within the dataset.\r\n\r\n![Filter Graph](https://drive.google.com/uc?id=0B4VJB4X3lwZGUVVWd0hTMW5jTDQ)\r\n\r\n### Plane Estimation\r\n\r\nTwo types of tests were run on the plane estimation stage of the algorithm. The first set of tests was performed to analyze on the accuracy of the algorithms for estimating the proper ground plane. As a result of a lack of labeled datasets for this work this set of tests was purely qualitative. Surprisingly all three algorithms returned very similar results, there were not discernable difference between any of the algorithms. Figure _ shows examples of multiple views of the input datasets (left) and the resulting set of inlier points (right). The top row demonstrates that using just plane extraction might be sufficient for datasets with a relatively uniform ground; however the second row demonstrates that such techniques fail when the scene consists nonplanar ground, such as hilly terrain.  \r\n \r\n![Plane Estimation](https://drive.google.com/uc?id=0B4VJB4X3lwZGMWZncDRRM0RxZzQ)\r\n\r\nThe second set of tests was performed to analyze the computation time of each of the three plane estimation algorithms. A plot of the execution times for the algorithms run on datasets with varying number of points can be seen in Figure _. In this figure it is clear that the RANSAC algorithm takes significantly longer than both the LMEDS algorithm and the PROSAC algorithm. This is consistent with the fact that LMEDS is less complex than RANSAC and does not require multiple iterations. Additionally PROSAC is a more recently developed algorithm that greedily selects the best matching points initially, thus reducing the wasted computations on poorly matching points. As a result of this test we recommend using the PROSAC plane fitting algorithm for future work.\r\n\r\n![Plane Est Graph](https://drive.google.com/uc?id=0B4VJB4X3lwZGYnBGUXJyVkVqNXc)\r\n\r\n### Segmentation\r\n\r\nTwo algorithms were tested for ground plane segmentation. The Graph Cuts algorithm gave mixed results. Since the algorithm utilizes the results of the plane estimation as its seed values it can only be as good as the estimation. This resulted in large gaps where the plane estimation stripped away elevation. Additionally, due to the graph cuts algorithm requiring the weighting function to be the 3D euclidian distance between points, it limited our ability to isolate the inconsistent points relative to their vertical position (as would be done ideally). An example of this can be seen in Figures _ and _. \r\n\r\n![Graph Cuts Orig](https://drive.google.com/uc?id=0B4VJB4X3lwZGZnFsQUN1eFlCdDA)\r\n\r\nThe Progressive Morphological filter produced an accurate ground plane. Almost all objects were removed from the data set and the ground points were kept intact. This can be seen in Figures _ and _. In both Figures the left image shows the original image and the right shows the output from the filter. It can be seen that the buildings and trees are properly removed, even off of the hill in Figure _ while keeping the terrain intact.\r\n\r\n![Prog One](https://drive.google.com/uc?id=0B4VJB4X3lwZGSXFQSzBUb1pYUkk)\r\n![Prog Two](https://drive.google.com/uc?id=0B4VJB4X3lwZGVlV6V2o0RWxxUDA)\r\n\r\nAs far as runtime performance is concerned the Progressive Morphological Filter ran slightly slower with data sets smaller than 50,000. After that threshold the Graph Cuts algorithm runtime sharply increased and the Progressive Morphological Filter became much more efficient. \r\n\r\n### Mesh Generation\r\n\r\nBy using the fast triangulation algorithm provided by the PCL library a mesh was generated for the extracted ground plane segment, which can be seen in Figure _. The resulting mesh was fairly accurate but had a few error points. There are gaps in some areas where the triangulation could not be completed. This is most likely a case where the no triangle could be made within the maximum inner angle threshold.\r\n\r\n![Mesh](https://drive.google.com/uc?id=0B4VJB4X3lwZGbW5KV18ya1B5UzQ)\r\n\r\n# 8. Challenges\r\n\r\nOver the course of our work we ran into multiple challenges ranging from installing and configuring the library to learning how to work with and manipulate point clouds and dealing with discrepancies between datasets. One of the most significant problems we encountered in this work was simply installing and configuring the PCL libraries. We tried multiple approaches to install it on two OSX machines as it was said to be compatible, however each failed. So instead we turned to Ubuntu and achieved more success after additional dead ends. It was quite frustrating to get the majority of the way through a compilation for a dependency version miss-match to cause the compilation to fail. However much was learned about library configuration so the process was not a complete waste.\r\n        \tAnother challenge was getting acclimated to working with point cloud data. Neither of us had any experience with point clouds in PCL nor any other environment, so there was an initial learning curve to the project. All previous experience was with dense data such imagery in 2D grids (pictures) or 3D matrices (ultrasound imagery). Thus working with sparse data required different techniques for efficient processing.\r\n        \tOriginally we were hoping to work on large dataset consisting of multiple scenes in Rochester created by the RIT college of imaging science. These datasets however presented two main difficulties. The first problem with the datasets was that we could not convert them from a standard “.LAS” file to the “.PCD” format that was required to load them with the PCL library. This was a significant problem seeing as most LiDAR data is in the “.LAS” format. We tried multiple software packages and libraries for converting the files but none seemed to work. Even if the conversion did work the secondary problem we ran into problem would have halted any further progress. The second problem we encountered was that the computer we were using for this work could not handle any significantly large dataset; the RIT datasets were much larger than anything we could get to process in a reasonable time. Therefor we used smaller public example datasets supplied by PCL.\r\n        \tAnother difficulty we encountered was that multiple datasets was collected using different LiDAR sensors with different sampling rates and scene sizes. This resulted in wildly varied input data to our algorithm. Because of the variability we noticed once we optimized the parameters for one stage for a given dataset it would fail for a different dataset. In order to mitigate this problem we normalized the data so that the scene was contained in a cube that was +/- one unit on each side. This normalization greatly improved the results across the datasets. \r\n\r\n\r\n# 9. Future Work\r\n\r\nAlthough this work was a great introductory experience for point clouds and the Point Cloud Library, it only scratched the surface of what can be done with LiDAR imagery from an aerial vehicle. As as result the number of potential avenues to be explored in the future are vast. The first area that would be good to explore is converting “.LAS” files to “.PCD” files so that a much larger library of datasets could be used. Additionally moving the processing to a more powerful machine would be beneficial for working on larger datasets. A more significant and impactful area to pursue is implementing segmentation algorithms based on custom rules and similarity metrics. PCL has modules that are extendable, thus making it easy to implement custom segmentation methods that will fit right into the library. Another area that could be investigated is looking into using Difference of Normals (DoNs) segmentation methods. This method could potentially be the most fruitful, because DoNs are very popular in the field. We were hoping the implement DoNs segmentation but we ran out of time unfortunately.  \r\n\r\n# 10. Conclusion\r\n\r\nAs depth sensors become less expensive and smaller the trend towards working with three dimensional is becoming increasingly apparent. Thus it is important to expose ourselves to 3D point clouds and the libraries that are commonly used to process them. This work serves as an introductory lesson in working with such point cloud data using the Point Cloud Library. Although we did not have time for custom implementations of algorithms in this work, its outcome was still a success because both of us have a much deeper understanding of how to work with point clouds using industry standard libraries. This work will undoubtedly serve as a personal stepping stone for future work in the area. \r\n\r\n# References\r\n\r\n[1. Martin A. Fischler and Robert C. Bolles (June 1981). \"Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography\" (PDF). Comm. of the ACM 24 (6): 381–395] (http://dl.acm.org/citation.cfm?id=358692)\r\n\r\n[2. Chum, Ondrej, and Jiri Matas. \"Matching with PROSAC-progressive sample consensus.\" Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on. Vol. 1. IEEE, 2005](http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=1467271&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D1467271)\r\n\r\n[3. Boykov, Y.; Kolmogorov, V., \"An experimental comparison of min-cut/max- flow algorithms for energy minimization in vision,\" Pattern Analysis and Machine Intelligence, IEEE Transactions on , vol.26, no.9, pp.1124,1137, Sept. 2004](http://www.csd.uwo.ca/~yuri/Papers/pami04.pdf)\r\n\r\n[4. Zhang, Keqi, et al. \"A progressive morphological filter for removing nonground measurements from airborne LIDAR data.\" Geoscience and Remote Sensing, IEEE Transactions on 41.4 (2003): 872-882.\r\n](https://cis.uab.edu/zhang/Promotion-Full-Professor-Application/publication-PDFs/TGRS03.pdf)\r\n\r\n# Libraries\r\n[PCL](http://docs.pointclouds.org/trunk/index.html)\r\n\r\n[VTK](http://vtk.org/)\r\n# Datasets\r\n[RIT Imaging Science One](http://dirsapps.cis.rit.edu/3d-rochester/data.html)\r\n\r\n[RIT Imaging Science Two](http://www.rit.edu/cos/share2012/downloadarea.php)","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}