<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Ground Plane Segmentation from Unstructured Point Clouds : Tim Fratangelo &amp; Bret Minnehan">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Ground Plane Segmentation from Unstructured Point Clouds</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/tfrat/lidar">View on GitHub</a>

          <h1 id="project_title">Ground Plane Segmentation from Unstructured Point Clouds</h1>
          <h2 id="project_tagline">Tim Fratangelo &amp; Bret Minnehan</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/tfrat/lidar/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/tfrat/lidar/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1>
<a id="1-overview-and-goals" class="anchor" href="#1-overview-and-goals" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Overview and Goals</h1>

<p>LiDAR (Light Detection and Ranging) sensors use time of flight measurements from a focused beam of light from a laser to measure the three-dimensional structure of an object or area.  LiDAR sensors have broad application to many domains including Archeology, Robotics, and Physics. As LiDAR sensors are decreasing in price and weight their use from aerial platforms is increasing. Aerial LiDAR imagery provides high-resolution topographic data for much cheaper than other methods. The data collected from LiDAR sensors are known as Point Clouds. Point Clouds are a series of points represented by their coordinates in the 3D Cartesian coordinate system.</p>

<p>This work is focused on processing the data collected from airborne LiDAR sensors to segment points belonging to the ground plane to points belonging to objects or structures. This ground plane segmentation is useful for many different applications, such as surveying, in which the area of focus is purely the ground plane. A traditional approach for ground plane segmentation can be seen in Figure 1. This figure demonstrates how an initial point cloud is input into a system then it is preprocessed using various methods such as normalization and resampling to insure consistency of point clouds for the system. After the point cloud is pre-processed it is filtered using one of many filtering methods. After filtering it is then a plane fitting method is used to find the plane that best fits the majority of the data. After the plane is fit to the data a segmentation algorithm is used to extract the points that are consistent with the plane given various constraints. After the segmentation the points are feed into a mesh generation algorithm, which generates a triangulated mesh from the points on the ground plane. The aim of this work was to test multiple commonly used methods for each of these steps and determine which methods were optimal, as will be discussed for the remainder of the work.</p>

<p><img src="https://drive.google.com/uc?id=0B4VJB4X3lwZGZjY5cnZaT29rNFE" alt="Pipeline"></p>

<p>The remainder of this site is organized as such: Section 2 discusses the configuration of the system used and the computer used for processing. Section 3 discusses the methods used for filtering the initial point cloud. Section 4 discusses the approaches for estimating the ground plane. Section 5 discusses the ground plane segmentation process. Section 6 outlines the steps taken for generating 3D triangulated meshes from a point cloud. Section 7 discusses the results from this work. Section 8 overviews some of the challenges encountered in this work. Finally Section 9 concludes and provides potential avenues for future work. </p>

<h1>
<a id="2-setup" class="anchor" href="#2-setup" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. Setup</h1>

<p>In this work we relied heavily on an open source C++ library known as the Point Cloud Library (PCL), which is supported by many large corporations in the 3D sensing industry. The library was compiled and used on a virtual machine running Ubuntu 15.04 with 16GB RAM, Intel i5 Processor.</p>

<h1>
<a id="3-filtering" class="anchor" href="#3-filtering" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. Filtering</h1>

<h2>
<a id="1-passthrough-filter" class="anchor" href="#1-passthrough-filter" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Passthrough Filter</h2>

<p>The passthrough filter relies on thresholding to eliminate points along a dimensional axis. By providing an upper and lower limit all points not within those bounds will be removed from the plot. Utilizing this filter for this project is not very beneficial as most LiDAR datasets deal with changes in elevation. As a result the data generally does not lie on a single plane. When the filter is applied, not only noise is eliminated but also important terrain points are removed as well.</p>

<h2>
<a id="2-radius-outlier-removal" class="anchor" href="#2-radius-outlier-removal" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. Radius Outlier Removal</h2>

<p>The radius outlier removal algorithm measures the amount of local neighbors for each point. A point can be considered to have neighbors is they lie within a preset spherical radius. If there are not enough neighbors within the radius the point is removed from the cloud. This works well with removing isolated outliers. However if there are a clusters of noise they will not be filtered out.</p>

<h2>
<a id="3-statistical-outlier-removal" class="anchor" href="#3-statistical-outlier-removal" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. Statistical Outlier Removal</h2>

<p>The statistical outlier removal algorithm filters is useful for removing measurement errors from LiDAR scans. This is done on a point by point basis. At each point the distance between each neighbor is used to calculate the mean and standard deviation. The amount of nearest neighbors for each point is passed as an argument to the algorithm along with the standard deviation threshold. If the point’s mean distance is larger than the standard deviation threshold </p>

<h1>
<a id="4-plane-estimation" class="anchor" href="#4-plane-estimation" aria-hidden="true"><span class="octicon octicon-link"></span></a>4. Plane Estimation</h1>

<p>The concept behind the plane estimation problems is attempting to find a planer model that best fits the input data. Plane estimation should theoretically be a simple task if the data is planar and noise free; however the point clouds resulting from LiDAR scans rarely fit such conditions. Due to the inconsistencies of the ground in most environments and the inherent noise in LiDAR data more robust planer estimation algorithms must be used. The PCL library implements multiple robust model fitting algorithm including, Least Median of Squares (LMEDS), Random Sample and Consensus (RANSAC), and Progressive Sample and Consensus (PROSAC). Each of these algorithms will be discussed further below. 
            The simplest of the three algorithms is Least Median of Squares[CITE], in this algorithm points in the dataset are randomly sampled in m groups which are then used to form m estimations for the model of the data. Once the models are calculated the residual for each point with respect to each model, how close is the point to fitting the model, is calculated. The score for each model is then determined by calculating the median of the residuals for all of the points. The median is used as opposed to the mean because the median has been shown to be more robust to outliers than the mean. The model that has the smallest median residual is then selected as the optimal model for the data.
One of if not the most used model fitting algorithms is the Random Sample and Consensus algorithm. Unlike LMEDS, RANSAC is an iterative probabilistic method for model fitting. In the RANSAC algorithm an initial set of point are randomly selected from the complete dataset, the set selected is the minimal set that will solve for the given parameters for the model. Once a model is fit to the initial set the residuals for all of the remaining points are calculated. Any point whose residual falls within a specified threshold is considered an inlier point, part of the consensus set, all other points are considered outliers. If a specified number of inliers are found the algorithm then attempts to update the model given the updated set, including the new inliers, then the residuals are recalculated and new inliers are added. This process repeats until a minimum confidence value is achieved on the model’s fit or a maximum number of iterations were reached. This method was originally designed for image alignment based on match landmarks in [Fischler], but has been adapted for countless applications that require fitting a model to data.<br>
The model-fitting algorithm used in this work that was most recently proposed was the Progressive Sample and Consensus algorithm [Chum]. The PROSAC method is an extension to the RANSAC method, with a slight alteration to the sampling procedure. Unlike RANSAC, which samples all point with equal probability, PROSAC relies on the quality of the correspondences selecting the points with the minimal residuals initially and progressively growing the set larger.  </p>

<h1>
<a id="5-segmentation" class="anchor" href="#5-segmentation" aria-hidden="true"><span class="octicon octicon-link"></span></a>5. Segmentation</h1>

<h2>
<a id="1-min-cuts--max-flow" class="anchor" href="#1-min-cuts--max-flow" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Min Cuts / Max Flow</h2>

<p>One of the most common modern segmentation techniques is an algorithm known as Graph Cuts (or Min cut/Max flow), popularized by [Boykov]. This algorithm is popular due to its adaptability and applicability to many problem domains. For the Graph Cuts algorithm a node on a bi-directional graph represents each point. Between each point is a connection that has a weight corresponding to the similarity between the two nodes. Part of the adaptability of the graph cuts method comes from the fact that the weighting function can be an arbitrary function that highlights desired seminaries between points. In image data it is common to connect each pixel with its surrounding pixels using the similarity of the intensity values as the weight metric.  For point clouds often the three dimensional Euclidian distance is used for the intra-point weights, as was done in this implementation. Unfortunately for the implementation of graph cuts supplied by PCL the weight metric could not be altered, which negatively affected the quality of results it produced. In addition to the intra-point weights there are also weights between each point and Source and Drain nodes. In most cases these weights can be determined using an arbitrary metric; however in this implementation the weights were determined based on the 3D Euclidian distance to “source points”. The goal of the graph cuts algorithm is to separate the graph into two subgraphs, one connected the source and one connected to the drain, with the minimal cut cost. For our implementation we were forced to use the 3D Euclidian distance for the weight metric and for the source points we used the inlier points from the plane estimation stage. </p>

<h2>
<a id="2-progressive-morphological-filter" class="anchor" href="#2-progressive-morphological-filter" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. Progressive Morphological Filter</h2>

<p>Progressive Morphological filters work to eliminate points that are not considered to be apart of the terrain in a point cloud data set. This is accomplished by using multiple iterations of a mathematical morphological filter on a two-dimensional grayscale image. This image is a top-down view of the LiDAR data set using the brightness of each pixel as the elevation value. Changes in elevation can be directly correlated to changes in graytone in the image. The morphological filter works by performing two operations, dilation and erosion. Dilation replaces the current pixel with the maximum value of the neighboring pixels surrounding it and erosion does the opposite and uses the minimum value. These two operations can be used in conjunction to create opening and closing techniques to filter LiDAR data. Opening consists of first eroding the image and then dilating, whereas closing is in the opposite order. By performing these two techniques small objects can be removed by erosion and then large terrain objects such as cliff faces can be restored using dilation. This technique is highly dependent on the window size used to select neighboring pixels. A window size too small can remove small objects on the ground but large objects such as buildings will remain. However, a large window size can remove valid ground points. As a pixel gains its value from the highest or lowest point in a certain window size it is of paramount importance that the dataset is filtered prior to running this algorithm. </p>

<p>Choosing a proper window size with a real world data set to accurately filter ground points cannot be feasible found. This problem is solved by using multiple iterations of the morphological filter using increased window sizes with each subsequent iteration. Each iteration feeds it output into the next run. The first few runs will removed the small objects in the scene such as trees or cars but will leave buildings in. Since those objects have been removed in previous iterations the larger window sizes will only encounter ground and properly iterate. The window size will eventually increase to a size that will encompass the tops of the buildings and they will be removed as well. This continues until a maximum window size has been reached. It is important to only choose a final window size that is just large enough to remove the largest object in the scene as to avoid over removing ground points. </p>

<p>A problem with this approach is that terrain with gradual increases in elevation have their tops flattened into a plateau shape. This is overcome by adding a elevation threshold parameter to the algorithm. The original point’s elevation is compared to the new filtered point’s elevation. If the difference is smaller than the threshold it is considered a ground point, otherwise it is removed. The threshold size also starts small and increases with each pass. This is to avoid keeping short objects such as trees in the first few passes. The result is an algorithm that can keep natural changes in elevations while removing unwanted objects. </p>

<h1>
<a id="6-mesh-generation" class="anchor" href="#6-mesh-generation" aria-hidden="true"><span class="octicon octicon-link"></span></a>6. Mesh Generation</h1>

<h1>
<a id="7-results" class="anchor" href="#7-results" aria-hidden="true"><span class="octicon octicon-link"></span></a>7. Results</h1>

<h1>
<a id="8-challenges" class="anchor" href="#8-challenges" aria-hidden="true"><span class="octicon octicon-link"></span></a>8. Challenges</h1>

<h1>
<a id="9-future-work" class="anchor" href="#9-future-work" aria-hidden="true"><span class="octicon octicon-link"></span></a>9. Future Work</h1>

<h1>
<a id="libraries" class="anchor" href="#libraries" aria-hidden="true"><span class="octicon octicon-link"></span></a>Libraries</h1>

<p><a href="http://docs.pointclouds.org/trunk/index.html">PCL</a></p>

<p><a href="http://vtk.org/">VTK</a></p>

<h1>
<a id="datasets" class="anchor" href="#datasets" aria-hidden="true"><span class="octicon octicon-link"></span></a>Datasets</h1>

<p><a href="http://dirsapps.cis.rit.edu/3d-rochester/data.html">RIT Imaging Science One</a></p>

<p><a href="http://www.rit.edu/cos/share2012/downloadarea.php">RIT Imaging Science Two</a></p>

<h1>
<a id="references" class="anchor" href="#references" aria-hidden="true"><span class="octicon octicon-link"></span></a>References</h1>

<p><a href="http://dl.acm.org/citation.cfm?id=358692">1. Martin A. Fischler and Robert C. Bolles (June 1981). "Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography" (PDF). Comm. of the ACM 24 (6): 381–395</a></p>

<p><a href="http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;arnumber=1467271&amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D1467271">2. Chum, Ondrej, and Jiri Matas. "Matching with PROSAC-progressive sample consensus." Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on. Vol. 1. IEEE, 2005</a></p>

<p><a href="http://www.csd.uwo.ca/%7Eyuri/Papers/pami04.pdf">3. Boykov, Y.; Kolmogorov, V., "An experimental comparison of min-cut/max- flow algorithms for energy minimization in vision," Pattern Analysis and Machine Intelligence, IEEE Transactions on , vol.26, no.9, pp.1124,1137, Sept. 2004</a></p>

<p><a href="https://cis.uab.edu/zhang/Promotion-Full-Professor-Application/publication-PDFs/TGRS03.pdf">4. Zhang, Keqi, et al. "A progressive morphological filter for removing nonground measurements from airborne LIDAR data." Geoscience and Remote Sensing, IEEE Transactions on 41.4 (2003): 872-882.
</a></p>

<p><a href="http://www.velodynelidar.com/lidar/hdlpressroom/pdf/papers/journal_papers/On%20the%20Segmentation%20of%203D%20LIDAR%20Point%20Clouds.pdf">On the Segmentation of 3D LIDAR Point Clouds
</a></p>

<p><a href="http://www.cs.princeton.edu/%7Efunk/s3dv09.pdf">Min-Cut Based Segmentation of Point Clouds</a></p>

<p><a href="http://www.asprs.org/a/publications/proceedings/baltimore09/0101.pdf">Segmentation of LIDAR Point Clouds For Building Extraction</a></p>

<p><a href="http://scholarworks.rit.edu/theses/960/">Automatic 3D Building Detection and Modeling from Airborne LiDAR Point Clouds</a></p>

<p><a href="http://www.sci.utah.edu/%7Eshachar/Publications/MLSMesh.pdf">Triangulating Point Set Surfaces with Bounded Error</a></p>

<p><a href="http://www.csd.uwo.ca/%7Eyuri/Papers/pami04.pdf">An Experimental Comparison of Min-Cut/Max-Flow Algorithms for Energy Minimization in Vision</a></p>

<p><a href="http://www.pf.bgu.tum.de/isprs/pia07/puba/PIA07_Dorninger_Nothegger.pdf">3D Segmentation of Unstructured Point Clouds for Building Modeling</a></p>

<p><a href="http://www.cis.rit.edu/%7Esxs4643/jstar_manu.pdf">Modeling 3D Urban Areas from Aerial LIDAR Point Clouds: A Robust Roof Feature Based Reconstruction Approach
</a></p>

<p><a href="http://www.cis.rit.edu/%7Esxs4643/IEEEsun1.pdf">Aerial 3D Building Detection and Modeling From Airborne LiDAR Point Clouds</a></p>

<p><a href="http://www.sci.utah.edu/%7Eshachar/Publications/MLSMesh.pdf">Triangulating Point Set Surfaces with Bounded Error</a></p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Ground Plane Segmentation from Unstructured Point Clouds maintained by <a href="https://github.com/tfrat">tfrat</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
